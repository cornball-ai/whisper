<!-- Generated by fyi::use_fyi_md() on 2026-01-19 -->
<!-- Regenerate with: fyi::use_fyi_md("whisper") -->

# fyi: whisper

## Exported Functions (whisper::)

| Function | Arguments |
|----------|-----------|
| `audio_to_mel` | file, n_mels, device, dtype |
| `download_whisper_model` | model, force |
| `list_downloaded_models` |  |
| `list_whisper_models` |  |
| `load_audio` | file |
| `load_whisper_model` | model, device, dtype, download |
| `transcribe` | file, model, language, task, timestamps, device, dtype, verbose |
| `whisper_config` | model |
| `whisper_device` |  |
| `whisper_dtype` | device |
| `whisper_tokenizer` | model, cache_dir |


## Internal Functions (whisper:::)

| Function | Arguments |
|----------|-----------|
| `.onLoad` | libname, pkgname |
| `apply_bpe` | tokens, merge_ranks |
| `audio_duration` | file |
| `byte_to_token` | byte |
| `clean_text` | text |
| `compute_stft` | audio, n_fft, hop_length |
| `copy_if_exists` | param, weights, name |
| `create_decoder` | config |
| `create_encoder` | config |
| `create_mel_filterbank_fallback` | n_fft, n_mels, sample_rate |
| `decode_bpe_bytes` | text |
| `decode_timestamp` | token_id |
| `download_tokenizer_files` | model, vocab_dir |
| `ensure_tokenizer_files` | model, cache_dir |
| `extract_segments` | tokens, tokenizer, time_offset |
| `get_initial_tokens` | language, task, timestamps |
| `get_model_path` | model |
| `get_weights_path` | model |
| `greedy_decode` | model, encoder_output, initial_tokens, tokenizer, max_length, device |
| `hz_to_mel` | hz |
| `is_timestamp_token` | token_id |
| `load_decoder_weights` | decoder, weights |
| `load_encoder_weights` | encoder, weights |
| `load_mel_filterbank` | n_mels |
| `load_whisper_weights` | model, weights_path |
| `mel_to_hz` | mel |
| `model_exists` | model |
| `pad_or_trim` | audio, length |
| `parse_device` | device |
| `parse_dtype` | dtype, device |
| `split_audio` | file, chunk_length, overlap |
| `tokenizer_decode` | ids, id_to_token, special_tokens |
| `tokenizer_encode` | text, vocab, merge_ranks |
| `transcribe_chunk` | file, model, tokenizer, config, language, task, timestamps, device, dtype, verbose |
| `transcribe_long` | file, model, tokenizer, config, language, task, timestamps, device, dtype, verbose |
| `whisper_attention` | n_state, n_head |
| `whisper_decoder` | n_vocab, n_ctx, n_state, n_head, n_layer |
| `whisper_decoder_layer` | n_state, n_head |
| `whisper_encoder` | n_mels, n_ctx, n_state, n_head, n_layer |
| `whisper_encoder_layer` | n_state, n_head |
| `whisper_lang_token` | lang |
| `whisper_model` | config |
| `whisper_special_tokens` |  |


## Options (whisper)

| Option | File | Type |
|--------|------|------|
| `whisper.cache_dir` | audio.R | get |
| `whisper.cache_dir` | tokenizer.R | get |
| `whisper.cache_dir` | zzz.R | set |


# Documentation: whisper

## apply_bpe

### Apply BPE Merges

#### Description

Apply BPE Merges

#### Usage

```r
apply_bpe(tokens, merge_ranks)
```

#### Arguments

- **`tokens`**: Character vector of tokens
- **`merge_ranks`**: Named vector of merge rankings

#### Value

Character vector after BPE merges


## audio_duration

### Get Audio Duration

#### Description

Get Audio Duration

#### Usage

```r
audio_duration(file)
```

#### Arguments

- **`file`**: Path to audio file

#### Value

Duration in seconds


## audio_to_mel

### Convert Audio to Mel Spectrogram

#### Description

Main preprocessing function that converts audio to the mel spectrogram
format expected by Whisper.

#### Usage

```r
audio_to_mel(file, n_mels = 80L, device = "auto", dtype = "auto")
```

#### Arguments

- **`file`**: Path to audio file, or numeric vector of audio samples
- **`n_mels`**: Number of mel bins (80 for most models, 128 for large-v3)
- **`device`**: torch device for output tensor
- **`dtype`**: torch dtype for output tensor

#### Value

torch tensor of shape (1, n_mels, 3000) for 30s audio


## byte_to_token

### Convert Byte to BPE Token

#### Description

GPT-2/Whisper uses a specific byte-to-unicode mapping.

#### Usage

```r
byte_to_token(byte)
```

#### Arguments

- **`byte`**: Integer byte value (0-255)

#### Value

Character token


## clean_text

### Clean Transcribed Text

#### Description

Clean Transcribed Text

#### Usage

```r
clean_text(text)
```

#### Arguments

- **`text`**: Raw decoded text

#### Value

Cleaned text


## compute_stft

### Compute STFT Magnitude

#### Description

Compute STFT Magnitude

#### Usage

```r
compute_stft(audio, n_fft = WHISPER_N_FFT, hop_length = WHISPER_HOP_LENGTH)
```

#### Arguments

- **`audio`**: Numeric vector of audio samples
- **`n_fft`**: FFT window size
- **`hop_length`**: Hop length between frames

#### Value

Complex STFT matrix


## copy_if_exists

### Copy Weight if Exists

#### Description

Copy Weight if Exists

#### Usage

```r
copy_if_exists(param, weights, name)
```

#### Arguments

- **`param`**: Target parameter
- **`weights`**: Weight dictionary
- **`name`**: Weight name


## create_decoder

### Create Decoder from Config

#### Description

Create Decoder from Config

#### Usage

```r
create_decoder(config)
```

#### Arguments

- **`config`**: Model configuration from whisper_config()

#### Value

WhisperDecoder module


## create_encoder

### Create Encoder from Config

#### Description

Create Encoder from Config

#### Usage

```r
create_encoder(config)
```

#### Arguments

- **`config`**: Model configuration from whisper_config()

#### Value

WhisperEncoder module


## create_mel_filterbank_fallback

### Create Mel Filterbank (Fallback)

#### Description

Create a mel filterbank matrix for converting STFT to mel spectrogram.
Used when pre-computed filterbank is not available.

#### Usage

```r
create_mel_filterbank_fallback(
  n_fft = WHISPER_N_FFT,
  n_mels = 80L,
  sample_rate = WHISPER_SAMPLE_RATE
)
```

#### Arguments

- **`n_fft`**: FFT size
- **`n_mels`**: Number of mel bins
- **`sample_rate`**: Audio sample rate

#### Value

Mel filterbank matrix (n_mels x n_freqs)


## create_mel_filterbank

### Create Mel Filterbank

#### Description

Create a mel filterbank matrix for converting STFT to mel spectrogram.

#### Usage

```r
create_mel_filterbank(
  n_fft = WHISPER_N_FFT,
  n_mels = 80L,
  sample_rate = WHISPER_SAMPLE_RATE
)
```

#### Arguments

- **`n_fft`**: FFT size
- **`n_mels`**: Number of mel bins
- **`sample_rate`**: Audio sample rate

#### Value

Mel filterbank matrix (n_mels x n_freqs)


## decode_bpe_bytes

### Decode BPE Bytes Back to Text

#### Description

Decode BPE Bytes Back to Text

#### Usage

```r
decode_bpe_bytes(text)
```

#### Arguments

- **`text`**: Text with BPE byte tokens

#### Value

Decoded text


## decode_timestamp

### Decode Timestamp Token

#### Description

Decode Timestamp Token

#### Usage

```r
decode_timestamp(token_id)
```

#### Arguments

- **`token_id`**: Token ID

#### Value

Time in seconds


## dot-onLoad

### Package Initialization

#### Description

Package Initialization

#### Usage

```r
.onLoad(libname, pkgname)
```

#### Arguments

- **`libname`**: Library name
- **`pkgname`**: Package name


## download_tokenizer_files

### Download Tokenizer Files from HuggingFace

#### Description

Download Tokenizer Files from HuggingFace

#### Usage

```r
download_tokenizer_files(model, vocab_dir)
```

#### Arguments

- **`model`**: Model name
- **`vocab_dir`**: Directory to save files (unused, kept for API compatibility)


## download_whisper_model

### Download Model from HuggingFace

#### Description

Download Model from HuggingFace

#### Usage

```r
download_whisper_model(model = "tiny", force = FALSE)
```

#### Arguments

- **`model`**: Model name
- **`force`**: Re-download even if exists

#### Value

Path to model directory


## ensure_tokenizer_files

### Ensure Tokenizer Files are Downloaded

#### Description

Ensure Tokenizer Files are Downloaded

#### Usage

```r
ensure_tokenizer_files(model, cache_dir)
```

#### Arguments

- **`model`**: Model name
- **`cache_dir`**: Cache directory (unused, kept for API compatibility)

#### Value

Path to vocab directory (directory containing vocab.json)


## extract_segments

### Extract Segments with Timestamps

#### Description

Extract Segments with Timestamps

#### Usage

```r
extract_segments(tokens, tokenizer, time_offset = 0)
```

#### Arguments

- **`tokens`**: Token IDs
- **`tokenizer`**: Tokenizer
- **`time_offset`**: Offset in seconds for chunk processing

#### Value

Data frame with start, end, text


## get_initial_tokens

### Get Initial Decoder Tokens

#### Description

Build the initial token sequence for decoder input.

#### Usage

```r
get_initial_tokens(language = "en", task = "transcribe", timestamps = TRUE)
```

#### Arguments

- **`language`**: Two-letter language code or NULL for auto
- **`task`**: "transcribe" or "translate"
- **`timestamps`**: Whether to include timestamps

#### Value

Integer vector of initial token IDs


## get_model_path

### Model Download Utilities

#### Description

Download Whisper models from HuggingFace using hfhub. Get Model Cache
Path

#### Usage

```r
get_model_path(model)
```

#### Arguments

- **`model`**: Model name

#### Value

Path to model directory in hfhub cache


## get_weights_path

### Get Path to Model Weights

#### Description

Get Path to Model Weights

#### Usage

```r
get_weights_path(model)
```

#### Arguments

- **`model`**: Model name

#### Value

Path to safetensors file


## greedy_decode

### Greedy Decoding

#### Description

Greedy Decoding

#### Usage

```r
greedy_decode(
  model,
  encoder_output,
  initial_tokens,
  tokenizer,
  max_length = 448L,
  device
)
```

#### Arguments

- **`model`**: WhisperModel
- **`encoder_output`**: Encoder hidden states
- **`initial_tokens`**: Initial token tensor
- **`tokenizer`**: Tokenizer
- **`max_length`**: Maximum output length
- **`device`**: Device

#### Value

Integer vector of generated tokens


## hz_to_mel

### Convert Hz to Mel Scale

#### Description

Convert Hz to Mel Scale

#### Usage

```r
hz_to_mel(hz)
```

#### Arguments

- **`hz`**: Frequency in Hz

#### Value

Frequency in mel scale


## is_timestamp_token

### Check if Token is Timestamp

#### Description

Check if Token is Timestamp

#### Usage

```r
is_timestamp_token(token_id)
```

#### Arguments

- **`token_id`**: Token ID

#### Value

TRUE if timestamp token


## list_downloaded_models

### List Downloaded Models

#### Description

List Downloaded Models

#### Usage

```r
list_downloaded_models()
```

#### Value

Character vector of downloaded model names


## list_whisper_models

### List Available Models

#### Description

List Available Models

#### Usage

```r
list_whisper_models()
```

#### Value

Character vector of model names


## load_audio

### Load and Preprocess Audio

#### Description

Load audio from file, convert to mono, resample to 16kHz.

#### Usage

```r
load_audio(file)
```

#### Arguments

- **`file`**: Path to audio file (WAV, MP3, etc.)

#### Value

Numeric vector of audio samples normalized to -1 to 1 range


## load_decoder_weights

### Load Decoder Weights

#### Description

Load Decoder Weights

#### Usage

```r
load_decoder_weights(decoder, weights)
```

#### Arguments

- **`decoder`**: WhisperDecoder module
- **`weights`**: Named list of tensors


## load_encoder_weights

### Load Encoder Weights

#### Description

Load Encoder Weights

#### Usage

```r
load_encoder_weights(encoder, weights)
```

#### Arguments

- **`encoder`**: WhisperEncoder module
- **`weights`**: Named list of tensors


## load_mel_filterbank

### Load Pre-computed Mel Filterbank

#### Description

Load the official Whisper mel filterbank from cached CSV file. Falls
back to computing on-the-fly if not available.

#### Usage

```r
load_mel_filterbank(n_mels = 80L)
```

#### Arguments

- **`n_mels`**: Number of mel bins (80 or 128)

#### Value

Mel filterbank matrix (n_mels x n_freqs)


## load_whisper_model

### Load Whisper Model

#### Description

Load a Whisper model with weights from HuggingFace.

#### Usage

```r
load_whisper_model(
  model = "tiny",
  device = "auto",
  dtype = "auto",
  download = TRUE
)
```

#### Arguments

- **`model`**: Model name: "tiny", "base", "small", "medium", "large-v3"
- **`device`**: Device to load model on ("auto", "cpu", "cuda")
- **`dtype`**: Data type ("auto", "float16", "float32")
- **`download`**: If TRUE, download model if not present

#### Value

WhisperModel module


## load_whisper_weights

### Load Weights from Safetensors

#### Description

Load Weights from Safetensors

#### Usage

```r
load_whisper_weights(model, weights_path)
```

#### Arguments

- **`model`**: WhisperModel module
- **`weights_path`**: Path to safetensors file


## mel_to_hz

### Convert Mel Scale to Hz

#### Description

Convert Mel Scale to Hz

#### Usage

```r
mel_to_hz(mel)
```

#### Arguments

- **`mel`**: Frequency in mel scale

#### Value

Frequency in Hz


## model_exists

### Check if Model is Downloaded

#### Description

Check if Model is Downloaded

#### Usage

```r
model_exists(model)
```

#### Arguments

- **`model`**: Model name

#### Value

TRUE if model weights exist locally


## pad_or_trim

### Pad or Trim Audio to Fixed Length

#### Description

Pad or Trim Audio to Fixed Length

#### Usage

```r
pad_or_trim(audio, length = WHISPER_N_SAMPLES)
```

#### Arguments

- **`audio`**: Numeric vector of audio samples
- **`length`**: Target length in samples (default: 30s at 16kHz)

#### Value

Numeric vector of specified length


## parse_device

### Parse Device Argument

#### Description

Parse Device Argument

#### Usage

```r
parse_device(device = "auto")
```

#### Arguments

- **`device`**: Character or torch device. "auto" uses GPU if available.

#### Value

torch device object


## parse_dtype

### Parse Dtype Argument

#### Description

Parse Dtype Argument

#### Usage

```r
parse_dtype(dtype = "auto", device = whisper_device())
```

#### Arguments

- **`dtype`**: Character or torch dtype. "auto" uses float16 on GPU, float32 on CPU.
- **`device`**: torch device (used for auto selection)

#### Value

torch dtype


## split_audio

### Split Long Audio into Chunks

#### Description

Split audio longer than 30 seconds into overlapping chunks.

#### Usage

```r
split_audio(file, chunk_length = 30, overlap = 1)
```

#### Arguments

- **`file`**: Path to audio file
- **`chunk_length`**: Chunk length in seconds
- **`overlap`**: Overlap between chunks in seconds

#### Value

List of audio chunks (numeric vectors)


## tokenizer_decode

### Decode Token IDs to Text

#### Description

Decode Token IDs to Text

#### Usage

```r
tokenizer_decode(ids, id_to_token, special_tokens)
```

#### Arguments

- **`ids`**: Integer vector of token IDs
- **`id_to_token`**: Mapping from ID to token
- **`special_tokens`**: Special token info

#### Value

Character string


## tokenizer_encode

### Encode Text to Token IDs

#### Description

Encode Text to Token IDs

#### Usage

```r
tokenizer_encode(text, vocab, merge_ranks)
```

#### Arguments

- **`text`**: Character string to encode
- **`vocab`**: Vocabulary mapping (token -> id)
- **`merge_ranks`**: Merge ranking for BPE

#### Value

Integer vector of token IDs


## transcribe_chunk

### Transcribe Single Chunk

#### Description

Transcribe Single Chunk

#### Usage

```r
transcribe_chunk(
  file,
  model,
  tokenizer,
  config,
  language = "en",
  task = "transcribe",
  timestamps = FALSE,
  device,
  dtype,
  verbose = TRUE
)
```

#### Arguments

- **`file`**: Audio file or mel spectrogram
- **`model`**: WhisperModel
- **`tokenizer`**: Tokenizer
- **`config`**: Model config
- **`language`**: Language code
- **`task`**: Task type
- **`timestamps`**: Include timestamps
- **`device`**: Device
- **`dtype`**: Dtype
- **`verbose`**: Verbose output

#### Value

Transcription result


## transcribe_long

### Transcribe Long Audio

#### Description

Process audio longer than 30 seconds in chunks.

#### Usage

```r
transcribe_long(
  file,
  model,
  tokenizer,
  config,
  language,
  task,
  timestamps,
  device,
  dtype,
  verbose
)
```

#### Arguments

- **`file`**: Audio file
- **`model`**: WhisperModel
- **`tokenizer`**: Tokenizer
- **`config`**: Model config
- **`language`**: Language
- **`task`**: Task
- **`timestamps`**: Timestamps
- **`device`**: Device
- **`dtype`**: Dtype
- **`verbose`**: Verbose

#### Value

Combined transcription result


## transcribe

### Whisper Transcription

#### Description

Main transcription API for Whisper. Transcribe Audio Transcribe speech
from an audio file using Whisper.

#### Usage

```r
transcribe(
  file,
  model = "tiny",
  language = "en",
  task = "transcribe",
  timestamps = FALSE,
  device = "auto",
  dtype = "auto",
  verbose = TRUE
)
```

#### Arguments

- **`file`**: Path to audio file (WAV, MP3, etc.)
- **`model`**: Model name: "tiny", "base", "small", "medium", "large-v3"
- **`language`**: Language code (e.g., "en", "es"). NULL for auto-detection.
- **`task`**: "transcribe" or "translate" (translate to English)
- **`timestamps`**: Include word/segment timestamps
- **`device`**: Device: "auto", "cpu", "cuda"
- **`dtype`**: Data type: "auto", "float16", "float32"
- **`verbose`**: Print progress messages

#### Value

List with text, segments, language, and metadata


## whisper_attention

### Whisper Encoder

#### Description

Transformer encoder for processing mel spectrograms. Multi-Head
Self-Attention

#### Usage

```r
whisper_attention(n_state, n_head)
```

#### Arguments

- **`n_state`**: Hidden dimension
- **`n_head`**: Number of attention heads


## whisper_config

### Whisper Model Configurations

#### Description

Get configuration for a Whisper model variant.

#### Usage

```r
whisper_config(model = "tiny")
```

#### Arguments

- **`model`**: Character. Model name: "tiny", "base", "small", "medium", "large-v3"

#### Value

List with model configuration parameters


## whisper_decoder_layer

### Whisper Decoder

#### Description

Transformer decoder with cross-attention to encoder outputs. Decoder
Layer Pre-norm transformer decoder layer with self-attention and
cross-attention.

#### Usage

```r
whisper_decoder_layer(n_state, n_head)
```

#### Arguments

- **`n_state`**: Hidden dimension
- **`n_head`**: Number of attention heads


## whisper_decoder

### Text Decoder

#### Description

Full Whisper decoder: token embedding + positional embedding +
transformer layers.

#### Usage

```r
whisper_decoder(n_vocab, n_ctx, n_state, n_head, n_layer)
```

#### Arguments

- **`n_vocab`**: Vocabulary size
- **`n_ctx`**: Maximum context length
- **`n_state`**: Hidden dimension
- **`n_head`**: Number of attention heads
- **`n_layer`**: Number of transformer layers


## whisper_device

### Device and Dtype Management

#### Description

Utilities for managing torch devices and data types. Get Default Device

#### Usage

```r
whisper_device()
```

#### Value

torch device object


## whisper_dtype

### Get Default Dtype

#### Description

Get Default Dtype

#### Usage

```r
whisper_dtype(device = whisper_device())
```

#### Arguments

- **`device`**: torch device

#### Value

torch dtype


## whisper_encoder_layer

### Encoder Layer

#### Description

Pre-norm transformer encoder layer.

#### Usage

```r
whisper_encoder_layer(n_state, n_head)
```

#### Arguments

- **`n_state`**: Hidden dimension
- **`n_head`**: Number of attention heads


## whisper_encoder

### Audio Encoder

#### Description

Full Whisper encoder: Conv stem + positional encoding + transformer
layers.

#### Usage

```r
whisper_encoder(n_mels, n_ctx, n_state, n_head, n_layer)
```

#### Arguments

- **`n_mels`**: Number of mel spectrogram bins
- **`n_ctx`**: Maximum context length (1500 for 30s audio)
- **`n_state`**: Hidden dimension
- **`n_head`**: Number of attention heads
- **`n_layer`**: Number of transformer layers


## whisper_lang_token

### Get Language Token ID

#### Description

Get Language Token ID

#### Usage

```r
whisper_lang_token(lang = "en")
```

#### Arguments

- **`lang`**: Two-letter language code (e.g., "en", "es", "fr")

#### Value

Token ID for the language


## whisper_model

### Whisper Model

#### Description

Full Whisper model combining encoder and decoder. Whisper Model Module

#### Usage

```r
whisper_model(config)
```

#### Arguments

- **`config`**: Model configuration


## WHISPER_SAMPLE_RATE

### Audio Preprocessing for Whisper

#### Description

Convert audio files to mel spectrograms for Whisper input. Whisper Audio
Constants


## whisper_special_tokens

### Special Token IDs

#### Description

Special Token IDs

#### Usage

```r
whisper_special_tokens()
```

#### Value

Named list of special token IDs


## whisper_tokenizer

### Whisper BPE Tokenizer

#### Description

Byte-pair encoding tokenizer for Whisper models. Create Whisper
Tokenizer Load or create a Whisper tokenizer from HuggingFace vocab
files.

#### Usage

```r
whisper_tokenizer(model = "tiny", cache_dir = getOption("whisper.cache_dir"))
```

#### Arguments

- **`model`**: Model name for vocab lookup
- **`cache_dir`**: Directory for cached vocab files

#### Value

Tokenizer object (list with encode/decode functions)


